<!DOCTYPE html>
<html lang="en-US">

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width,maximum-scale=2">
    <link rel="stylesheet" type="text/css" media="screen" href="/assets/css/style.css?v=4347d9b846f2cebdc47e657f7c3c9e451d3ad96a">
    <!-- Mathjax Support -->
    <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Introduction | alexandervandekleut.github.io</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Introduction" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Introduction" />
<meta property="og:description" content="Introduction" />
<link rel="canonical" href="http://localhost:4000/introduction/" />
<meta property="og:url" content="http://localhost:4000/introduction/" />
<meta property="og:site_name" content="alexandervandekleut.github.io" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2019-05-12T00:00:00-04:00" />
<script type="application/ld+json">
{"description":"Introduction","@type":"BlogPosting","url":"http://localhost:4000/introduction/","headline":"Introduction","dateModified":"2019-05-12T00:00:00-04:00","datePublished":"2019-05-12T00:00:00-04:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/introduction/"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <h1 id="project_title"> TF 2.0 for Reinforcement Learning </h1>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        
        <h4>
          <a href="http://localhost:4000">Home</a>
        </h4>
        
        
        <h1 id="introduction">Introduction</h1>

<p>Reinforcement learning has become extremely popular lately. Advances in techniques and distributed processing has allowed reinforcement learning agents to <a href="https://deepmind.com/research/alphago/">beat the world champion at Go</a> and <a href="https://openai.com/five/">play competitively against world leaders at Dota 2</a>.</p>

<p>In this series, we build up a deep theoretical understanding of reinforcement learning by combining theory and implementations. We will be using the <a href="https://www.python.org/">Python</a> programming language, along with an assortment of libraries such as <a href="https://www.numpy.org">numpy</a>, <a href="https://www.tensorflow.org/">tensorflow</a>, and <a href="https://gym.openai.com/">gym</a>. We assume the reader has familiarity with programming in Python. We will also be making extensive use of <a href="https://jupyter.org/">jupyter notebooks</a>.</p>

<hr />

<h3 id="the-basic-reinforcement-learning-loop">The Basic Reinforcement Learning Loop</h3>

<p>There are two main entities in reinforcement learning: the <strong>agent</strong> and the <strong>environment</strong>.</p>

<p style="text-align:center"><img src="http://localhost:4000/assets/images/rl.png" alt="rl-loop" /></p>

<p>The agent is responsible for choosing <strong>actions</strong> <script type="math/tex">a_t</script> based on the current <strong>state</strong> <script type="math/tex">s_t</script>. In turn, the environment changes according the action that the agent took. The environment then provides the agent with the next state <script type="math/tex">s_{t+1}</script>, and also a <strong>reward</strong> <script type="math/tex">r_t</script> that represents how good or bad it was to choose that action in that state.</p>

<p>The driving idea behind reinforcement learning is the <strong>reward hypothesis</strong>:</p>

<blockquote>
  <p>Every action of a rational agent can be thought of as seeking to maximize some cumulative scalar reward signal.</p>
</blockquote>

<p>Our goal is for the agent to learn a <strong>policy</strong>, a set of rules for choosing actions based on the current state, that maximizes the cumulative rewards.</p>

<p>Over the course of several lessons, we will build up an understanding of two main classes of policies:<strong>$Q$-learning$$</strong> and <strong>policy gradients</strong>.</p>

<hr />
<h3 id="who-is-this-for">Who is this for?</h3>

<p>When writing my undergraduate thesis in reinforcement learning, I found plenty of resources spread across the internet. <a href="https://medium.com/@jonathan_hui">Some pages</a> were extremely helpful in understanding the theoretical underpinnings of reinforcement learning, whereas <a href="https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0">others</a> focused mostly on code and spent very little time on theory. Furthermore, there are <a href="https://github.com/openai/baselines">open source implementations</a> of many reinforcement learning techniques with little explanation as to how the code actually <em>works</em>. I decided to put together a comprehensive resource that provides clear explanations of the theory behind reinforcement learning, combined with high-quality implementations of each algorithm to help you go from theory to implementation when you decide to try something out for yourself.</p>

<p>Most resources out there use <code class="highlighter-rouge">tensorflow 1.x</code>, but since that is going to be phased out this year (2019), I have decided to learn and use <code class="highlighter-rouge">tensorflow 2.0a</code> instead. <code class="highlighter-rouge">tensorflow 2</code> is written with the imperative nature of python in mind, so it runs using ‘eager execution’ and ‘gradient tapes’ rather than using predefined ‘sessions’ (as you will often see in older implementations). Most of this guide was written during the alpha and beta release.</p>

<p>I assume you have the required mathematical background to understand machine learning concepts:</p>

<ul>
  <li>Statistics and probability theory (understanding what an expectation is and how to evaluate it)</li>
  <li>Linear algebra (vector math)</li>
  <li>Multivariate calculus (gradients)</li>
</ul>

        
        <h4>
          <a href="http://localhost:4000">Home</a>
        </h4>
        
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        
        <p class="copyright">alexandervandekleut.github.io maintained by <a href="https://github.com/alexandervandekleut">alexandervandekleut</a></p>
        
      </footer>
    </div>

    
  </body>
</html>
