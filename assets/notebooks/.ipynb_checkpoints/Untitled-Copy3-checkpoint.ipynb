{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"CartPole-v0\"\n",
    "\n",
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "MEMORY_SIZE = 1000000\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "n_epsilon=0.1\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.01\n",
    "EXPLORATION_DECAY = 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space, num_envs):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.num_envs = num_envs\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(24, input_shape=(observation_space,), activation=\"relu\", use_bias='false', kernel_initializer='he_uniform'))\n",
    "        self.model.add(Dense(24, activation=\"relu\", use_bias='false', kernel_initializer='he_uniform'))\n",
    "        self.model.add(Dense(self.action_space, activation=\"linear\", use_bias='false', kernel_initializer='zeros'))\n",
    "        self.optimizer = tf.keras.optimizers.SGD(LEARNING_RATE)\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            return np.random.randint(self.action_space, size=self.num_envs)\n",
    "        q_values = self.model(state)\n",
    "        return np.argmax(q_values, axis=1)\n",
    "    \n",
    "    def decay_epsilon(self, n):\n",
    "#         self.exploration_rate *= EXPLORATION_DECAY\n",
    "#         self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, EXPLORATION_MAX - (n/n_epsilon)*(EXPLORATION_MAX - EXPLORATION_MIN))\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        for state, action, reward, state_next, terminal in batch:\n",
    "            with tf.GradientTape() as tape:\n",
    "                Q_next = tf.stop_gradient(tf.reduce_max(self.model(state_next), axis=1))\n",
    "                Q_pred = tf.reduce_sum(self.model(state)*tf.one_hot(action, self.action_space, dtype=tf.float32), axis=1)\n",
    "                loss = tf.reduce_mean(0.5*(reward + (1-terminal)*GAMMA*Q_next - Q_pred)**2)\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizedEnvWrapper(gym.Wrapper):\n",
    "    def __init__(self, make_env, num_envs=1):\n",
    "        super().__init__(make_env())\n",
    "        self.num_envs = num_envs\n",
    "        self.envs = [make_env() for env_index in range(num_envs)]\n",
    "    \n",
    "    def reset(self):\n",
    "        return np.asarray([env.reset() for env in self.envs])\n",
    "    \n",
    "    def reset_at(self, env_index):\n",
    "        return self.envs[env_index].reset()\n",
    "    \n",
    "    def step(self, actions):\n",
    "        next_states, rewards, dones, infos = [], [], [], []\n",
    "        for env, action in zip(self.envs, actions):\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_states.append(next_state)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "            infos.append(info)\n",
    "        return np.asarray(next_states), np.asarray(rewards), \\\n",
    "            np.asarray(dones), np.asarray(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(T=20000, num_envs=32):\n",
    "    env = VectorizedEnvWrapper(lambda: gym.make(ENV_NAME), num_envs)\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "    dqn_solver = DQNSolver(observation_space, action_space, num_envs)\n",
    "    rewards = []\n",
    "    episode_rewards = 0\n",
    "    state = env.reset()\n",
    "    for t in range(T):\n",
    "        action = dqn_solver.act(state)\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        dqn_solver.remember(state, action, reward, state_next, terminal)\n",
    "        state = state_next\n",
    "        dqn_solver.experience_replay()\n",
    "        dqn_solver.decay_epsilon(t/T)\n",
    "        episode_rewards += reward\n",
    "\n",
    "        for i in range(env.num_envs):\n",
    "            if terminal[i]:\n",
    "                print(\"exploration: \" + str(dqn_solver.exploration_rate) + \", score: \" + str(episode_rewards[i]))\n",
    "                rewards.append(episode_rewards[i])\n",
    "                episode_rewards[i] = 0\n",
    "                state[i] = env.reset_at(i)\n",
    "    return episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration: 0.99208, score: 9.0\n",
      "exploration: 0.9901, score: 11.0\n",
      "exploration: 0.9901, score: 11.0\n",
      "exploration: 0.9901, score: 11.0\n",
      "exploration: 0.9901, score: 11.0\n",
      "exploration: 0.98911, score: 12.0\n",
      "exploration: 0.98911, score: 12.0\n",
      "exploration: 0.98911, score: 12.0\n",
      "exploration: 0.98812, score: 13.0\n",
      "exploration: 0.98713, score: 14.0\n",
      "exploration: 0.98614, score: 15.0\n",
      "exploration: 0.98515, score: 16.0\n",
      "exploration: 0.98515, score: 16.0\n",
      "exploration: 0.98416, score: 17.0\n",
      "exploration: 0.98317, score: 18.0\n",
      "exploration: 0.98317, score: 18.0\n",
      "exploration: 0.98218, score: 19.0\n",
      "exploration: 0.98218, score: 19.0\n",
      "exploration: 0.98218, score: 19.0\n",
      "exploration: 0.98218, score: 19.0\n",
      "exploration: 0.98119, score: 20.0\n",
      "exploration: 0.9802, score: 21.0\n",
      "exploration: 0.97822, score: 23.0\n",
      "exploration: 0.97822, score: 23.0\n",
      "exploration: 0.97723, score: 12.0\n",
      "exploration: 0.97723, score: 11.0\n",
      "exploration: 0.97624, score: 25.0\n",
      "exploration: 0.97624, score: 25.0\n",
      "exploration: 0.97525, score: 12.0\n",
      "exploration: 0.97525, score: 26.0\n",
      "exploration: 0.97228, score: 29.0\n",
      "exploration: 0.97228, score: 29.0\n",
      "exploration: 0.97228, score: 13.0\n",
      "exploration: 0.97129, score: 19.0\n",
      "exploration: 0.9703, score: 16.0\n",
      "exploration: 0.96931, score: 32.0\n",
      "exploration: 0.96832, score: 10.0\n",
      "exploration: 0.96832, score: 21.0\n",
      "exploration: 0.96832, score: 16.0\n",
      "exploration: 0.96733, score: 23.0\n",
      "exploration: 0.96733, score: 34.0\n",
      "exploration: 0.96535, score: 12.0\n",
      "exploration: 0.96436, score: 16.0\n",
      "exploration: 0.96436, score: 26.0\n",
      "exploration: 0.96436, score: 21.0\n",
      "exploration: 0.9633700000000001, score: 19.0\n",
      "exploration: 0.96139, score: 21.0\n",
      "exploration: 0.96139, score: 22.0\n",
      "exploration: 0.96139, score: 29.0\n",
      "exploration: 0.9604, score: 18.0\n",
      "exploration: 0.95743, score: 14.0\n",
      "exploration: 0.95545, score: 34.0\n",
      "exploration: 0.95545, score: 17.0\n",
      "exploration: 0.95446, score: 11.0\n",
      "exploration: 0.95347, score: 14.0\n",
      "exploration: 0.95347, score: 28.0\n",
      "exploration: 0.95248, score: 49.0\n",
      "exploration: 0.95248, score: 15.0\n",
      "exploration: 0.95248, score: 16.0\n",
      "exploration: 0.95248, score: 18.0\n",
      "exploration: 0.95149, score: 31.0\n",
      "exploration: 0.95149, score: 41.0\n",
      "exploration: 0.95149, score: 25.0\n",
      "exploration: 0.95149, score: 31.0\n",
      "exploration: 0.94951, score: 15.0\n",
      "exploration: 0.94951, score: 26.0\n",
      "exploration: 0.94852, score: 20.0\n",
      "exploration: 0.94852, score: 12.0\n",
      "exploration: 0.94753, score: 17.0\n",
      "exploration: 0.94555, score: 30.0\n",
      "exploration: 0.94456, score: 28.0\n",
      "exploration: 0.94456, score: 28.0\n",
      "exploration: 0.94357, score: 10.0\n",
      "exploration: 0.94258, score: 13.0\n",
      "exploration: 0.94159, score: 42.0\n",
      "exploration: 0.94159, score: 22.0\n",
      "exploration: 0.94159, score: 36.0\n",
      "exploration: 0.9396100000000001, score: 12.0\n",
      "exploration: 0.93862, score: 38.0\n",
      "exploration: 0.93763, score: 14.0\n",
      "exploration: 0.93763, score: 17.0\n",
      "exploration: 0.93565, score: 14.0\n",
      "exploration: 0.93565, score: 22.0\n",
      "exploration: 0.93367, score: 28.0\n",
      "exploration: 0.93367, score: 19.0\n",
      "exploration: 0.93367, score: 35.0\n",
      "exploration: 0.93268, score: 19.0\n",
      "exploration: 0.93169, score: 30.0\n",
      "exploration: 0.9307, score: 39.0\n",
      "exploration: 0.92971, score: 14.0\n",
      "exploration: 0.92971, score: 35.0\n",
      "exploration: 0.92872, score: 10.0\n",
      "exploration: 0.92872, score: 13.0\n",
      "exploration: 0.9277299999999999, score: 15.0\n",
      "exploration: 0.9277299999999999, score: 28.0\n",
      "exploration: 0.9277299999999999, score: 22.0\n",
      "exploration: 0.92674, score: 21.0\n",
      "exploration: 0.92674, score: 15.0\n",
      "exploration: 0.92674, score: 26.0\n",
      "exploration: 0.92476, score: 28.0\n",
      "exploration: 0.92377, score: 21.0\n",
      "exploration: 0.92278, score: 30.0\n",
      "exploration: 0.9208, score: 28.0\n",
      "exploration: 0.9208, score: 13.0\n",
      "exploration: 0.91981, score: 14.0\n",
      "exploration: 0.91882, score: 43.0\n",
      "exploration: 0.91783, score: 10.0\n",
      "exploration: 0.91783, score: 31.0\n",
      "exploration: 0.91783, score: 28.0\n",
      "exploration: 0.91783, score: 18.0\n",
      "exploration: 0.91486, score: 18.0\n",
      "exploration: 0.91486, score: 13.0\n",
      "exploration: 0.91387, score: 17.0\n",
      "exploration: 0.91288, score: 16.0\n",
      "exploration: 0.91189, score: 13.0\n",
      "exploration: 0.9109, score: 34.0\n",
      "exploration: 0.9109, score: 17.0\n",
      "exploration: 0.90991, score: 24.0\n",
      "exploration: 0.90892, score: 12.0\n",
      "exploration: 0.90892, score: 11.0\n",
      "exploration: 0.90793, score: 10.0\n",
      "exploration: 0.90793, score: 16.0\n",
      "exploration: 0.90694, score: 33.0\n",
      "exploration: 0.90595, score: 17.0\n",
      "exploration: 0.90595, score: 24.0\n",
      "exploration: 0.90496, score: 33.0\n",
      "exploration: 0.90496, score: 22.0\n",
      "exploration: 0.9039699999999999, score: 23.0\n",
      "exploration: 0.9039699999999999, score: 15.0\n",
      "exploration: 0.90298, score: 49.0\n",
      "exploration: 0.90199, score: 13.0\n",
      "exploration: 0.901, score: 29.0\n",
      "exploration: 0.90001, score: 12.0\n",
      "exploration: 0.90001, score: 10.0\n",
      "exploration: 0.90001, score: 15.0\n",
      "exploration: 0.89803, score: 20.0\n",
      "exploration: 0.89803, score: 20.0\n",
      "exploration: 0.8970400000000001, score: 16.0\n",
      "exploration: 0.8970400000000001, score: 17.0\n",
      "exploration: 0.8970400000000001, score: 14.0\n",
      "exploration: 0.89605, score: 15.0\n",
      "exploration: 0.89407, score: 33.0\n",
      "exploration: 0.89308, score: 43.0\n",
      "exploration: 0.89308, score: 13.0\n",
      "exploration: 0.89308, score: 16.0\n",
      "exploration: 0.89209, score: 15.0\n",
      "exploration: 0.89209, score: 50.0\n",
      "exploration: 0.89209, score: 62.0\n",
      "exploration: 0.8911, score: 13.0\n",
      "exploration: 0.89011, score: 14.0\n",
      "exploration: 0.88912, score: 11.0\n",
      "exploration: 0.88813, score: 13.0\n",
      "exploration: 0.88813, score: 12.0\n",
      "exploration: 0.88813, score: 14.0\n",
      "exploration: 0.88714, score: 42.0\n",
      "exploration: 0.88714, score: 10.0\n",
      "exploration: 0.88516, score: 47.0\n",
      "exploration: 0.88417, score: 16.0\n",
      "exploration: 0.8812, score: 22.0\n",
      "exploration: 0.88021, score: 28.0\n",
      "exploration: 0.88021, score: 16.0\n",
      "exploration: 0.88021, score: 38.0\n",
      "exploration: 0.87922, score: 18.0\n",
      "exploration: 0.87823, score: 60.0\n",
      "exploration: 0.87724, score: 16.0\n",
      "exploration: 0.87625, score: 21.0\n",
      "exploration: 0.87625, score: 9.0\n",
      "exploration: 0.87625, score: 12.0\n",
      "exploration: 0.87427, score: 13.0\n",
      "exploration: 0.87427, score: 31.0\n",
      "exploration: 0.87427, score: 13.0\n",
      "exploration: 0.8732800000000001, score: 36.0\n",
      "exploration: 0.87229, score: 20.0\n",
      "exploration: 0.87229, score: 16.0\n",
      "exploration: 0.87229, score: 21.0\n",
      "exploration: 0.8713, score: 34.0\n",
      "exploration: 0.87031, score: 36.0\n",
      "exploration: 0.87031, score: 22.0\n",
      "exploration: 0.86932, score: 20.0\n",
      "exploration: 0.86932, score: 29.0\n",
      "exploration: 0.86932, score: 29.0\n",
      "exploration: 0.86635, score: 14.0\n",
      "exploration: 0.8643700000000001, score: 27.0\n",
      "exploration: 0.86338, score: 30.0\n",
      "exploration: 0.86338, score: 58.0\n",
      "exploration: 0.86239, score: 17.0\n",
      "exploration: 0.86239, score: 15.0\n",
      "exploration: 0.86239, score: 19.0\n",
      "exploration: 0.86239, score: 16.0\n",
      "exploration: 0.8614, score: 19.0\n",
      "exploration: 0.8614, score: 12.0\n",
      "exploration: 0.86041, score: 34.0\n",
      "exploration: 0.8594200000000001, score: 33.0\n",
      "exploration: 0.85744, score: 13.0\n",
      "exploration: 0.85744, score: 19.0\n",
      "exploration: 0.85645, score: 16.0\n",
      "exploration: 0.85546, score: 16.0\n",
      "exploration: 0.85546, score: 17.0\n",
      "exploration: 0.85546, score: 21.0\n",
      "exploration: 0.85546, score: 14.0\n",
      "exploration: 0.85546, score: 19.0\n",
      "exploration: 0.85546, score: 33.0\n",
      "exploration: 0.8544700000000001, score: 9.0\n",
      "exploration: 0.8544700000000001, score: 10.0\n",
      "exploration: 0.8544700000000001, score: 12.0\n",
      "exploration: 0.85249, score: 10.0\n",
      "exploration: 0.85249, score: 22.0\n",
      "exploration: 0.8515, score: 57.0\n",
      "exploration: 0.8515, score: 10.0\n",
      "exploration: 0.85051, score: 34.0\n",
      "exploration: 0.84853, score: 14.0\n",
      "exploration: 0.84853, score: 24.0\n",
      "exploration: 0.84754, score: 12.0\n",
      "exploration: 0.84655, score: 24.0\n",
      "exploration: 0.8455600000000001, score: 24.0\n",
      "exploration: 0.8455600000000001, score: 17.0\n",
      "exploration: 0.84358, score: 11.0\n",
      "exploration: 0.84358, score: 13.0\n",
      "exploration: 0.84358, score: 12.0\n",
      "exploration: 0.84358, score: 17.0\n",
      "exploration: 0.84259, score: 34.0\n",
      "exploration: 0.8416, score: 9.0\n",
      "exploration: 0.8416, score: 13.0\n",
      "exploration: 0.8406100000000001, score: 15.0\n",
      "exploration: 0.8406100000000001, score: 15.0\n",
      "exploration: 0.83962, score: 16.0\n",
      "exploration: 0.83962, score: 13.0\n",
      "exploration: 0.8376399999999999, score: 26.0\n",
      "exploration: 0.83665, score: 26.0\n",
      "exploration: 0.8356600000000001, score: 10.0\n",
      "exploration: 0.8356600000000001, score: 13.0\n",
      "exploration: 0.83467, score: 21.0\n",
      "exploration: 0.83467, score: 14.0\n",
      "exploration: 0.83467, score: 13.0\n",
      "exploration: 0.83368, score: 19.0\n",
      "exploration: 0.83368, score: 28.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration: 0.83269, score: 9.0\n",
      "exploration: 0.83269, score: 23.0\n",
      "exploration: 0.8317, score: 23.0\n",
      "exploration: 0.82972, score: 22.0\n",
      "exploration: 0.82972, score: 14.0\n",
      "exploration: 0.82972, score: 61.0\n",
      "exploration: 0.82873, score: 46.0\n",
      "exploration: 0.82873, score: 41.0\n",
      "exploration: 0.82774, score: 53.0\n",
      "exploration: 0.82774, score: 12.0\n",
      "exploration: 0.82576, score: 12.0\n",
      "exploration: 0.82477, score: 19.0\n",
      "exploration: 0.82477, score: 16.0\n",
      "exploration: 0.82378, score: 11.0\n",
      "exploration: 0.82378, score: 34.0\n",
      "exploration: 0.82279, score: 14.0\n",
      "exploration: 0.82279, score: 19.0\n",
      "exploration: 0.82279, score: 9.0\n",
      "exploration: 0.82279, score: 11.0\n",
      "exploration: 0.8218000000000001, score: 14.0\n",
      "exploration: 0.8218000000000001, score: 13.0\n",
      "exploration: 0.82081, score: 12.0\n",
      "exploration: 0.82081, score: 12.0\n",
      "exploration: 0.82081, score: 25.0\n",
      "exploration: 0.81982, score: 23.0\n",
      "exploration: 0.81982, score: 9.0\n",
      "exploration: 0.81883, score: 11.0\n",
      "exploration: 0.81883, score: 11.0\n",
      "exploration: 0.81784, score: 12.0\n",
      "exploration: 0.81784, score: 34.0\n",
      "exploration: 0.8168500000000001, score: 12.0\n",
      "exploration: 0.8168500000000001, score: 11.0\n",
      "exploration: 0.81586, score: 20.0\n",
      "exploration: 0.81586, score: 19.0\n",
      "exploration: 0.81586, score: 28.0\n",
      "exploration: 0.81487, score: 19.0\n",
      "exploration: 0.81487, score: 43.0\n",
      "exploration: 0.8138799999999999, score: 30.0\n",
      "exploration: 0.8138799999999999, score: 9.0\n",
      "exploration: 0.81289, score: 27.0\n",
      "exploration: 0.8119000000000001, score: 29.0\n",
      "exploration: 0.8119000000000001, score: 13.0\n",
      "exploration: 0.80992, score: 15.0\n",
      "exploration: 0.80893, score: 15.0\n",
      "exploration: 0.80893, score: 15.0\n",
      "exploration: 0.80794, score: 15.0\n",
      "exploration: 0.80794, score: 39.0\n",
      "exploration: 0.80794, score: 13.0\n",
      "exploration: 0.80596, score: 22.0\n",
      "exploration: 0.80497, score: 18.0\n",
      "exploration: 0.80101, score: 11.0\n",
      "exploration: 0.80101, score: 17.0\n",
      "exploration: 0.79903, score: 21.0\n",
      "exploration: 0.79804, score: 14.0\n",
      "exploration: 0.79804, score: 24.0\n",
      "exploration: 0.79705, score: 16.0\n",
      "exploration: 0.79606, score: 25.0\n",
      "exploration: 0.7930900000000001, score: 22.0\n",
      "exploration: 0.7921, score: 24.0\n",
      "exploration: 0.79111, score: 23.0\n",
      "exploration: 0.78913, score: 33.0\n",
      "exploration: 0.7881400000000001, score: 31.0\n",
      "exploration: 0.78616, score: 31.0\n",
      "exploration: 0.78616, score: 30.0\n",
      "exploration: 0.78517, score: 25.0\n",
      "exploration: 0.78418, score: 22.0\n",
      "exploration: 0.78319, score: 35.0\n",
      "exploration: 0.7822, score: 34.0\n",
      "exploration: 0.77824, score: 41.0\n",
      "exploration: 0.7762600000000001, score: 25.0\n",
      "exploration: 0.77131, score: 37.0\n",
      "exploration: 0.77032, score: 53.0\n",
      "exploration: 0.77032, score: 47.0\n",
      "exploration: 0.76735, score: 42.0\n",
      "exploration: 0.76636, score: 30.0\n",
      "exploration: 0.76636, score: 26.0\n",
      "exploration: 0.7624, score: 37.0\n",
      "exploration: 0.76141, score: 47.0\n",
      "exploration: 0.76042, score: 60.0\n",
      "exploration: 0.75844, score: 43.0\n",
      "exploration: 0.75844, score: 39.0\n",
      "exploration: 0.75844, score: 18.0\n",
      "exploration: 0.75745, score: 28.0\n",
      "exploration: 0.75745, score: 25.0\n",
      "exploration: 0.75745, score: 36.0\n",
      "exploration: 0.75646, score: 33.0\n",
      "exploration: 0.75646, score: 59.0\n",
      "exploration: 0.75646, score: 14.0\n",
      "exploration: 0.75151, score: 32.0\n",
      "exploration: 0.74953, score: 60.0\n",
      "exploration: 0.74953, score: 37.0\n",
      "exploration: 0.74755, score: 41.0\n",
      "exploration: 0.74755, score: 51.0\n",
      "exploration: 0.74656, score: 11.0\n",
      "exploration: 0.7455700000000001, score: 69.0\n",
      "exploration: 0.74458, score: 26.0\n",
      "exploration: 0.74458, score: 27.0\n",
      "exploration: 0.74161, score: 50.0\n",
      "exploration: 0.7406200000000001, score: 11.0\n",
      "exploration: 0.7406200000000001, score: 26.0\n",
      "exploration: 0.73963, score: 17.0\n",
      "exploration: 0.73963, score: 39.0\n",
      "exploration: 0.73864, score: 29.0\n",
      "exploration: 0.73864, score: 22.0\n",
      "exploration: 0.7366600000000001, score: 85.0\n",
      "exploration: 0.73468, score: 23.0\n",
      "exploration: 0.73468, score: 15.0\n",
      "exploration: 0.7336900000000001, score: 29.0\n",
      "exploration: 0.7336900000000001, score: 53.0\n",
      "exploration: 0.7327, score: 13.0\n",
      "exploration: 0.7327, score: 14.0\n",
      "exploration: 0.7317100000000001, score: 25.0\n",
      "exploration: 0.7317100000000001, score: 18.0\n",
      "exploration: 0.73072, score: 68.0\n",
      "exploration: 0.73072, score: 36.0\n",
      "exploration: 0.72973, score: 29.0\n",
      "exploration: 0.72874, score: 16.0\n",
      "exploration: 0.72775, score: 31.0\n",
      "exploration: 0.72577, score: 101.0\n",
      "exploration: 0.72577, score: 16.0\n",
      "exploration: 0.72577, score: 15.0\n",
      "exploration: 0.72577, score: 14.0\n",
      "exploration: 0.72379, score: 85.0\n",
      "exploration: 0.72379, score: 24.0\n",
      "exploration: 0.7228000000000001, score: 17.0\n",
      "exploration: 0.7218100000000001, score: 10.0\n",
      "exploration: 0.7218100000000001, score: 17.0\n",
      "exploration: 0.72082, score: 10.0\n",
      "exploration: 0.72082, score: 85.0\n",
      "exploration: 0.71884, score: 22.0\n",
      "exploration: 0.7178500000000001, score: 40.0\n",
      "exploration: 0.71587, score: 46.0\n",
      "exploration: 0.71488, score: 33.0\n",
      "exploration: 0.71389, score: 12.0\n",
      "exploration: 0.7129000000000001, score: 17.0\n",
      "exploration: 0.7129000000000001, score: 24.0\n",
      "exploration: 0.71092, score: 34.0\n",
      "exploration: 0.70993, score: 16.0\n",
      "exploration: 0.70894, score: 23.0\n",
      "exploration: 0.70894, score: 30.0\n",
      "exploration: 0.70894, score: 15.0\n",
      "exploration: 0.70696, score: 22.0\n",
      "exploration: 0.70597, score: 29.0\n",
      "exploration: 0.70597, score: 27.0\n",
      "exploration: 0.7049799999999999, score: 18.0\n",
      "exploration: 0.7049799999999999, score: 17.0\n",
      "exploration: 0.7049799999999999, score: 28.0\n",
      "exploration: 0.69409, score: 30.0\n",
      "exploration: 0.6931, score: 21.0\n",
      "exploration: 0.6931, score: 23.0\n",
      "exploration: 0.69013, score: 16.0\n",
      "exploration: 0.69013, score: 67.0\n",
      "exploration: 0.6891400000000001, score: 18.0\n",
      "exploration: 0.6891400000000001, score: 37.0\n",
      "exploration: 0.6891400000000001, score: 16.0\n",
      "exploration: 0.6861700000000001, score: 36.0\n",
      "exploration: 0.6841900000000001, score: 51.0\n",
      "exploration: 0.6841900000000001, score: 50.0\n",
      "exploration: 0.6792400000000001, score: 106.0\n",
      "exploration: 0.67825, score: 43.0\n",
      "exploration: 0.67627, score: 30.0\n",
      "exploration: 0.6742900000000001, score: 35.0\n",
      "exploration: 0.6733, score: 48.0\n",
      "exploration: 0.6733, score: 21.0\n",
      "exploration: 0.6733, score: 55.0\n",
      "exploration: 0.67231, score: 54.0\n",
      "exploration: 0.67231, score: 46.0\n",
      "exploration: 0.67132, score: 44.0\n",
      "exploration: 0.67033, score: 40.0\n",
      "exploration: 0.66934, score: 36.0\n",
      "exploration: 0.6673600000000001, score: 17.0\n",
      "exploration: 0.66637, score: 20.0\n",
      "exploration: 0.6653800000000001, score: 48.0\n",
      "exploration: 0.6634, score: 46.0\n",
      "exploration: 0.66241, score: 57.0\n",
      "exploration: 0.65845, score: 35.0\n",
      "exploration: 0.6554800000000001, score: 21.0\n",
      "exploration: 0.65449, score: 55.0\n",
      "exploration: 0.65449, score: 35.0\n",
      "exploration: 0.65251, score: 53.0\n",
      "exploration: 0.6515200000000001, score: 22.0\n",
      "exploration: 0.6515200000000001, score: 20.0\n",
      "exploration: 0.65053, score: 13.0\n",
      "exploration: 0.64954, score: 21.0\n",
      "exploration: 0.64954, score: 62.0\n",
      "exploration: 0.6485500000000001, score: 14.0\n",
      "exploration: 0.64756, score: 43.0\n",
      "exploration: 0.6465700000000001, score: 38.0\n",
      "exploration: 0.64558, score: 27.0\n",
      "exploration: 0.64558, score: 29.0\n",
      "exploration: 0.64558, score: 34.0\n",
      "exploration: 0.6416200000000001, score: 48.0\n",
      "exploration: 0.64063, score: 32.0\n",
      "exploration: 0.63766, score: 94.0\n",
      "exploration: 0.63568, score: 38.0\n",
      "exploration: 0.63568, score: 58.0\n",
      "exploration: 0.6337, score: 57.0\n",
      "exploration: 0.63271, score: 33.0\n",
      "exploration: 0.6317200000000001, score: 38.0\n",
      "exploration: 0.6317200000000001, score: 15.0\n",
      "exploration: 0.6317200000000001, score: 24.0\n",
      "exploration: 0.62875, score: 61.0\n",
      "exploration: 0.62875, score: 23.0\n",
      "exploration: 0.62875, score: 17.0\n",
      "exploration: 0.6238000000000001, score: 35.0\n",
      "exploration: 0.6238000000000001, score: 22.0\n",
      "exploration: 0.62281, score: 30.0\n",
      "exploration: 0.62281, score: 45.0\n",
      "exploration: 0.62281, score: 27.0\n",
      "exploration: 0.62182, score: 26.0\n",
      "exploration: 0.6178600000000001, score: 14.0\n",
      "exploration: 0.6178600000000001, score: 142.0\n",
      "exploration: 0.6178600000000001, score: 32.0\n",
      "exploration: 0.61687, score: 57.0\n",
      "exploration: 0.6139000000000001, score: 20.0\n",
      "exploration: 0.6139000000000001, score: 41.0\n",
      "exploration: 0.6129100000000001, score: 29.0\n",
      "exploration: 0.60598, score: 30.0\n",
      "exploration: 0.60499, score: 24.0\n",
      "exploration: 0.6040000000000001, score: 47.0\n",
      "exploration: 0.6040000000000001, score: 32.0\n",
      "exploration: 0.60202, score: 16.0\n",
      "exploration: 0.60103, score: 37.0\n",
      "exploration: 0.60103, score: 28.0\n",
      "exploration: 0.60103, score: 13.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration: 0.59806, score: 69.0\n",
      "exploration: 0.59707, score: 36.0\n",
      "exploration: 0.5960799999999999, score: 22.0\n",
      "exploration: 0.59212, score: 57.0\n",
      "exploration: 0.58816, score: 53.0\n",
      "exploration: 0.58717, score: 18.0\n",
      "exploration: 0.5861800000000001, score: 46.0\n",
      "exploration: 0.5812300000000001, score: 42.0\n",
      "exploration: 0.5812300000000001, score: 43.0\n",
      "exploration: 0.5802400000000001, score: 72.0\n",
      "exploration: 0.57826, score: 39.0\n",
      "exploration: 0.57826, score: 68.0\n",
      "exploration: 0.57826, score: 35.0\n",
      "exploration: 0.57826, score: 51.0\n",
      "exploration: 0.5762800000000001, score: 28.0\n",
      "exploration: 0.5752900000000001, score: 39.0\n",
      "exploration: 0.56935, score: 145.0\n",
      "exploration: 0.5614300000000001, score: 174.0\n",
      "exploration: 0.56044, score: 62.0\n",
      "exploration: 0.56044, score: 46.0\n",
      "exploration: 0.5574700000000001, score: 66.0\n",
      "exploration: 0.55549, score: 23.0\n",
      "exploration: 0.55351, score: 70.0\n",
      "exploration: 0.5515300000000001, score: 81.0\n",
      "exploration: 0.5515300000000001, score: 128.0\n",
      "exploration: 0.54559, score: 59.0\n",
      "exploration: 0.53965, score: 30.0\n",
      "exploration: 0.53965, score: 58.0\n",
      "exploration: 0.5376700000000001, score: 44.0\n",
      "exploration: 0.53569, score: 67.0\n",
      "exploration: 0.5297499999999999, score: 89.0\n",
      "exploration: 0.52678, score: 61.0\n",
      "exploration: 0.52678, score: 75.0\n",
      "exploration: 0.52678, score: 70.0\n",
      "exploration: 0.5188600000000001, score: 83.0\n",
      "exploration: 0.5059899999999999, score: 81.0\n",
      "exploration: 0.505, score: 22.0\n",
      "exploration: 0.5040100000000001, score: 57.0\n",
      "exploration: 0.50302, score: 78.0\n",
      "exploration: 0.5010399999999999, score: 78.0\n",
      "exploration: 0.4970800000000001, score: 105.0\n",
      "exploration: 0.4970800000000001, score: 96.0\n",
      "exploration: 0.4970800000000001, score: 39.0\n",
      "exploration: 0.49609000000000003, score: 31.0\n",
      "exploration: 0.4951000000000001, score: 161.0\n",
      "exploration: 0.49411000000000005, score: 68.0\n",
      "exploration: 0.49312, score: 63.0\n",
      "exploration: 0.49114, score: 91.0\n",
      "exploration: 0.48817, score: 16.0\n",
      "exploration: 0.48619, score: 41.0\n",
      "exploration: 0.47728000000000004, score: 112.0\n",
      "exploration: 0.47134, score: 69.0\n",
      "exploration: 0.46936, score: 50.0\n",
      "exploration: 0.46936, score: 92.0\n",
      "exploration: 0.46638999999999997, score: 110.0\n",
      "exploration: 0.46540000000000004, score: 87.0\n",
      "exploration: 0.46441, score: 88.0\n",
      "exploration: 0.46342000000000005, score: 83.0\n",
      "exploration: 0.4624300000000001, score: 96.0\n",
      "exploration: 0.4624300000000001, score: 115.0\n",
      "exploration: 0.4574800000000001, score: 122.0\n",
      "exploration: 0.45154000000000005, score: 89.0\n",
      "exploration: 0.44857, score: 21.0\n",
      "exploration: 0.4337200000000001, score: 166.0\n",
      "exploration: 0.4287700000000001, score: 69.0\n",
      "exploration: 0.42580000000000007, score: 200.0\n",
      "exploration: 0.42481, score: 155.0\n",
      "exploration: 0.4188700000000001, score: 46.0\n",
      "exploration: 0.4119400000000001, score: 85.0\n",
      "exploration: 0.40996, score: 94.0\n",
      "exploration: 0.40897000000000006, score: 93.0\n",
      "exploration: 0.406, score: 125.0\n",
      "exploration: 0.406, score: 133.0\n",
      "exploration: 0.39808, score: 96.0\n",
      "exploration: 0.38917, score: 100.0\n",
      "exploration: 0.38817999999999997, score: 110.0\n",
      "exploration: 0.38322999999999996, score: 112.0\n",
      "exploration: 0.38026000000000004, score: 86.0\n",
      "exploration: 0.3772900000000001, score: 93.0\n",
      "exploration: 0.3723400000000001, score: 183.0\n",
      "exploration: 0.37036, score: 36.0\n",
      "exploration: 0.3644200000000001, score: 62.0\n",
      "exploration: 0.3535300000000001, score: 96.0\n",
      "exploration: 0.35056, score: 142.0\n",
      "exploration: 0.35056, score: 157.0\n",
      "exploration: 0.34957000000000005, score: 80.0\n",
      "exploration: 0.34065999999999996, score: 127.0\n",
      "exploration: 0.34065999999999996, score: 112.0\n",
      "exploration: 0.3386800000000001, score: 71.0\n",
      "exploration: 0.33570999999999995, score: 75.0\n",
      "exploration: 0.33274000000000004, score: 146.0\n",
      "exploration: 0.32878000000000007, score: 84.0\n",
      "exploration: 0.31888000000000005, score: 145.0\n",
      "exploration: 0.30699999999999994, score: 200.0\n",
      "exploration: 0.30699999999999994, score: 83.0\n",
      "exploration: 0.29908, score: 200.0\n",
      "exploration: 0.29710000000000014, score: 200.0\n",
      "exploration: 0.29413, score: 87.0\n",
      "exploration: 0.28819000000000006, score: 200.0\n",
      "exploration: 0.27928, score: 128.0\n",
      "exploration: 0.27928, score: 110.0\n",
      "exploration: 0.2743300000000001, score: 161.0\n",
      "exploration: 0.27334, score: 200.0\n",
      "exploration: 0.26542, score: 200.0\n",
      "exploration: 0.26443000000000005, score: 200.0\n",
      "exploration: 0.25948000000000004, score: 200.0\n",
      "exploration: 0.25156, score: 148.0\n",
      "exploration: 0.24364000000000008, score: 177.0\n",
      "exploration: 0.24265000000000014, score: 136.0\n",
      "exploration: 0.22680999999999996, score: 200.0\n",
      "exploration: 0.20700999999999992, score: 178.0\n",
      "exploration: 0.18523, score: 181.0\n",
      "exploration: 0.17434000000000005, score: 200.0\n",
      "exploration: 0.17236000000000018, score: 200.0\n",
      "exploration: 0.15553000000000006, score: 200.0\n",
      "exploration: 0.15256000000000014, score: 200.0\n",
      "exploration: 0.15256000000000014, score: 200.0\n",
      "exploration: 0.15156999999999998, score: 200.0\n",
      "exploration: 0.14266000000000012, score: 200.0\n",
      "exploration: 0.14266000000000012, score: 200.0\n",
      "exploration: 0.14068000000000003, score: 200.0\n",
      "exploration: 0.1377100000000001, score: 200.0\n",
      "exploration: 0.13473999999999997, score: 200.0\n",
      "exploration: 0.13078, score: 200.0\n",
      "exploration: 0.12087999999999999, score: 200.0\n",
      "exploration: 0.1090000000000001, score: 200.0\n",
      "exploration: 0.1090000000000001, score: 200.0\n",
      "exploration: 0.10107999999999995, score: 200.0\n",
      "exploration: 0.09910000000000008, score: 200.0\n",
      "exploration: 0.09612999999999994, score: 200.0\n",
      "exploration: 0.0901900000000001, score: 200.0\n",
      "exploration: 0.08623000000000003, score: 195.0\n",
      "exploration: 0.08425000000000005, score: 169.0\n",
      "exploration: 0.08128000000000002, score: 200.0\n",
      "exploration: 0.07633000000000012, score: 200.0\n",
      "exploration: 0.07534000000000007, score: 200.0\n",
      "exploration: 0.06741999999999992, score: 200.0\n",
      "exploration: 0.0664300000000001, score: 200.0\n",
      "exploration: 0.06148000000000009, score: 200.0\n",
      "exploration: 0.045640000000000014, score: 200.0\n",
      "exploration: 0.04465000000000008, score: 200.0\n",
      "exploration: 0.028810000000000002, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 185.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 176.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 193.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-ab8125a8f4a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrewards\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-d06855697c5a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(T, num_envs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdqn_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdqn_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mdqn_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecay_epsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mepisode_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-87abd946062a>\u001b[0m in \u001b[0;36mexperience_replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mQ_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterminal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mQ_next\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mQ_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   \u001b[0;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m   \u001b[0msum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0minput_0_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minput_0_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_0_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    808\u001b[0m   \"\"\"\n\u001b[1;32m    809\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    767\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Resource handles are not convertible to numpy.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cpu_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_cpu_nograd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    950\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mCPU\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0mbacked\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mcontents\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m     \"\"\"\n\u001b[0;32m--> 952\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_nograd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"CPU:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_copy_nograd\u001b[0;34m(self, ctx, device_name)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m       \u001b[0mnew_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rewards = train(T=10000, num_envs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
