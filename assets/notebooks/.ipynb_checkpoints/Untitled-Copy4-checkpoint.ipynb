{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = \"CartPole-v0\"\n",
    "\n",
    "MEMORY_SIZE = 1000000\n",
    "BATCH_SIZE = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self, observation_space, num_actions, num_envs, alpha=0.001, gamma=0.95, epsilon_i=1.0, epsilon_f=0.01, n_epsilon=0.1):\n",
    "        self.epsilon_i = epsilon_i\n",
    "        self.epsilon_f = epsilon_f\n",
    "        self.n_epsilon = n_epsilon\n",
    "        self.epsilon = epsilon_i\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.num_actions = num_actions\n",
    "        self.num_envs = num_envs\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "        self.Q = Sequential()\n",
    "        self.Q.add(Dense(24, input_shape=(observation_space,), activation=\"relu\", use_bias='false', kernel_initializer='he_uniform'))\n",
    "        self.Q.add(Dense(24, activation=\"relu\", use_bias='false', kernel_initializer='he_uniform'))\n",
    "        self.Q.add(Dense(self.num_actions, activation=\"linear\", use_bias='false', kernel_initializer='zeros'))\n",
    "        self.optimizer = tf.keras.optimizers.SGD(alpha)\n",
    "\n",
    "    def remember(self, s_t, a_t, r_t, s_t_next, done):\n",
    "        self.memory.append((s_t, a_t, r_t, s_t_next, done))\n",
    "\n",
    "    def act(self, s_t):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(self.num_actions, size=self.num_envs)\n",
    "        q_values = self.Q(s_t)\n",
    "        return np.argmax(q_values, axis=1)\n",
    "    \n",
    "    def decay_epsilon(self, n):\n",
    "        self.epsilon = max(\n",
    "            self.epsilon_f, \n",
    "            self.epsilon_i - (n/self.n_epsilon)*(self.epsilon_i - self.epsilon_f))\n",
    "\n",
    "    def experience_replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        for s_t, a_t, r_t, s_t_next, d_t in batch:\n",
    "            with tf.GradientTape() as tape:\n",
    "                Q_next = tf.stop_gradient(tf.reduce_max(self.Q(s_t_next), axis=1))\n",
    "                Q_pred = tf.reduce_sum(self.Q(s_t)*tf.one_hot(a_t, self.num_actions, dtype=tf.float32), axis=1)\n",
    "                loss = tf.reduce_mean(0.5*(r_t + (1-d_t)*self.gamma*Q_next - Q_pred)**2)\n",
    "            grads = tape.gradient(loss, self.Q.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.Q.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizedEnvWrapper(gym.Wrapper):\n",
    "    def __init__(self, make_env, num_envs=1):\n",
    "        super().__init__(make_env())\n",
    "        self.num_envs = num_envs\n",
    "        self.envs = [make_env() for env_index in range(num_envs)]\n",
    "    \n",
    "    def reset(self):\n",
    "        return np.asarray([env.reset() for env in self.envs])\n",
    "    \n",
    "    def reset_at(self, env_index):\n",
    "        return self.envs[env_index].reset()\n",
    "    \n",
    "    def step(self, actions):\n",
    "        next_states, rewards, dones, infos = [], [], [], []\n",
    "        for env, action in zip(self.envs, actions):\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            next_states.append(next_state)\n",
    "            rewards.append(reward)\n",
    "            dones.append(done)\n",
    "            infos.append(info)\n",
    "        return np.asarray(next_states), np.asarray(rewards), \\\n",
    "            np.asarray(dones), np.asarray(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(T=20000, num_envs=32):\n",
    "    env = VectorizedEnvWrapper(lambda: gym.make(ENV_NAME), num_envs)\n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    num_actions = env.action_space.n\n",
    "    agent = Agent(observation_space, num_actions, num_envs)\n",
    "    rewards = []\n",
    "    episode_rewards = 0\n",
    "    s_t = env.reset()\n",
    "    for t in range(T):\n",
    "        a_t = agent.act(s_t)\n",
    "        s_t_next, r_t, d_t, info = env.step(a_t)\n",
    "        agent.remember(s_t, a_t, r_t, s_t_next, d_t)\n",
    "        s_t = s_t_next\n",
    "        agent.experience_replay()\n",
    "        agent.decay_epsilon(t/T)\n",
    "        episode_rewards += r_t\n",
    "\n",
    "        for i in range(env.num_envs):\n",
    "            if d_t[i]:\n",
    "                print(\"exploration: \" + str(agent.epsilon) + \", score: \" + str(episode_rewards[i]))\n",
    "                rewards.append(episode_rewards[i])\n",
    "                episode_rewards[i] = 0\n",
    "                s_t[i] = env.reset_at(i)\n",
    "    return episode_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0610 17:01:20.609395 4556862912 deprecation.py:323] From /anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1205: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration: 0.99109, score: 10.0\n",
      "exploration: 0.99109, score: 10.0\n",
      "exploration: 0.9901, score: 11.0\n",
      "exploration: 0.98911, score: 12.0\n",
      "exploration: 0.98812, score: 13.0\n",
      "exploration: 0.98812, score: 13.0\n",
      "exploration: 0.98812, score: 13.0\n",
      "exploration: 0.98614, score: 15.0\n",
      "exploration: 0.98614, score: 15.0\n",
      "exploration: 0.98614, score: 15.0\n",
      "exploration: 0.98416, score: 17.0\n",
      "exploration: 0.98218, score: 19.0\n",
      "exploration: 0.98218, score: 19.0\n",
      "exploration: 0.98119, score: 20.0\n",
      "exploration: 0.98119, score: 20.0\n",
      "exploration: 0.98119, score: 20.0\n",
      "exploration: 0.97921, score: 22.0\n",
      "exploration: 0.97723, score: 24.0\n",
      "exploration: 0.97723, score: 24.0\n",
      "exploration: 0.97723, score: 14.0\n",
      "exploration: 0.97723, score: 24.0\n",
      "exploration: 0.97723, score: 24.0\n",
      "exploration: 0.97723, score: 24.0\n",
      "exploration: 0.97624, score: 12.0\n",
      "exploration: 0.97525, score: 15.0\n",
      "exploration: 0.97327, score: 16.0\n",
      "exploration: 0.97327, score: 28.0\n",
      "exploration: 0.97327, score: 28.0\n",
      "exploration: 0.97228, score: 9.0\n",
      "exploration: 0.97129, score: 30.0\n",
      "exploration: 0.97129, score: 17.0\n",
      "exploration: 0.9703, score: 11.0\n",
      "exploration: 0.9703, score: 16.0\n",
      "exploration: 0.9703, score: 11.0\n",
      "exploration: 0.96931, score: 32.0\n",
      "exploration: 0.96931, score: 32.0\n",
      "exploration: 0.96832, score: 20.0\n",
      "exploration: 0.96832, score: 18.0\n",
      "exploration: 0.96832, score: 23.0\n",
      "exploration: 0.96535, score: 19.0\n",
      "exploration: 0.96535, score: 17.0\n",
      "exploration: 0.96436, score: 13.0\n",
      "exploration: 0.96436, score: 13.0\n",
      "exploration: 0.9633700000000001, score: 23.0\n",
      "exploration: 0.96238, score: 11.0\n",
      "exploration: 0.96139, score: 14.0\n",
      "exploration: 0.96139, score: 12.0\n",
      "exploration: 0.96139, score: 40.0\n",
      "exploration: 0.96139, score: 40.0\n",
      "exploration: 0.9604, score: 16.0\n",
      "exploration: 0.95941, score: 13.0\n",
      "exploration: 0.95941, score: 9.0\n",
      "exploration: 0.95842, score: 21.0\n",
      "exploration: 0.95842, score: 11.0\n",
      "exploration: 0.95743, score: 16.0\n",
      "exploration: 0.95743, score: 20.0\n",
      "exploration: 0.95743, score: 44.0\n",
      "exploration: 0.95644, score: 12.0\n",
      "exploration: 0.95644, score: 15.0\n",
      "exploration: 0.95644, score: 14.0\n",
      "exploration: 0.95545, score: 16.0\n",
      "exploration: 0.95446, score: 47.0\n",
      "exploration: 0.95347, score: 24.0\n",
      "exploration: 0.9505, score: 27.0\n",
      "exploration: 0.9505, score: 14.0\n",
      "exploration: 0.9505, score: 15.0\n",
      "exploration: 0.94852, score: 29.0\n",
      "exploration: 0.94852, score: 13.0\n",
      "exploration: 0.94753, score: 21.0\n",
      "exploration: 0.94654, score: 12.0\n",
      "exploration: 0.94654, score: 10.0\n",
      "exploration: 0.94555, score: 19.0\n",
      "exploration: 0.94456, score: 14.0\n",
      "exploration: 0.94456, score: 12.0\n",
      "exploration: 0.94456, score: 26.0\n",
      "exploration: 0.94456, score: 10.0\n",
      "exploration: 0.94357, score: 16.0\n",
      "exploration: 0.94357, score: 17.0\n",
      "exploration: 0.94357, score: 22.0\n",
      "exploration: 0.94258, score: 15.0\n",
      "exploration: 0.94258, score: 17.0\n",
      "exploration: 0.94258, score: 27.0\n",
      "exploration: 0.94258, score: 19.0\n",
      "exploration: 0.94258, score: 19.0\n",
      "exploration: 0.94159, score: 9.0\n",
      "exploration: 0.94159, score: 14.0\n",
      "exploration: 0.9396100000000001, score: 22.0\n",
      "exploration: 0.93862, score: 15.0\n",
      "exploration: 0.93862, score: 12.0\n",
      "exploration: 0.93862, score: 9.0\n",
      "exploration: 0.93763, score: 20.0\n",
      "exploration: 0.93763, score: 19.0\n",
      "exploration: 0.93763, score: 26.0\n",
      "exploration: 0.93664, score: 26.0\n",
      "exploration: 0.93367, score: 9.0\n",
      "exploration: 0.93367, score: 68.0\n",
      "exploration: 0.93367, score: 24.0\n",
      "exploration: 0.93268, score: 16.0\n",
      "exploration: 0.93169, score: 12.0\n",
      "exploration: 0.93169, score: 15.0\n",
      "exploration: 0.9307, score: 16.0\n",
      "exploration: 0.9307, score: 52.0\n",
      "exploration: 0.9307, score: 14.0\n",
      "exploration: 0.92971, score: 13.0\n",
      "exploration: 0.92872, score: 22.0\n",
      "exploration: 0.92872, score: 15.0\n",
      "exploration: 0.9277299999999999, score: 17.0\n",
      "exploration: 0.9277299999999999, score: 12.0\n",
      "exploration: 0.92674, score: 12.0\n",
      "exploration: 0.92575, score: 23.0\n",
      "exploration: 0.92476, score: 17.0\n",
      "exploration: 0.92476, score: 18.0\n",
      "exploration: 0.92377, score: 20.0\n",
      "exploration: 0.92377, score: 14.0\n",
      "exploration: 0.92377, score: 22.0\n",
      "exploration: 0.92377, score: 19.0\n",
      "exploration: 0.92278, score: 22.0\n",
      "exploration: 0.92179, score: 16.0\n",
      "exploration: 0.92179, score: 17.0\n",
      "exploration: 0.92179, score: 21.0\n",
      "exploration: 0.92179, score: 12.0\n",
      "exploration: 0.9208, score: 13.0\n",
      "exploration: 0.91981, score: 11.0\n",
      "exploration: 0.91981, score: 18.0\n",
      "exploration: 0.91882, score: 14.0\n",
      "exploration: 0.91783, score: 53.0\n",
      "exploration: 0.91684, score: 14.0\n",
      "exploration: 0.91585, score: 12.0\n",
      "exploration: 0.91585, score: 13.0\n",
      "exploration: 0.91486, score: 19.0\n",
      "exploration: 0.91486, score: 24.0\n",
      "exploration: 0.91387, score: 18.0\n",
      "exploration: 0.91387, score: 10.0\n",
      "exploration: 0.91387, score: 17.0\n",
      "exploration: 0.91288, score: 11.0\n",
      "exploration: 0.91288, score: 13.0\n",
      "exploration: 0.91288, score: 12.0\n",
      "exploration: 0.91189, score: 20.0\n",
      "exploration: 0.9109, score: 11.0\n",
      "exploration: 0.90991, score: 12.0\n",
      "exploration: 0.90991, score: 19.0\n",
      "exploration: 0.90991, score: 35.0\n",
      "exploration: 0.90793, score: 13.0\n",
      "exploration: 0.90793, score: 12.0\n",
      "exploration: 0.90694, score: 15.0\n",
      "exploration: 0.90694, score: 10.0\n",
      "exploration: 0.90595, score: 18.0\n",
      "exploration: 0.90496, score: 11.0\n",
      "exploration: 0.90496, score: 18.0\n",
      "exploration: 0.9039699999999999, score: 10.0\n",
      "exploration: 0.9039699999999999, score: 14.0\n",
      "exploration: 0.9039699999999999, score: 33.0\n",
      "exploration: 0.9039699999999999, score: 15.0\n",
      "exploration: 0.9039699999999999, score: 24.0\n",
      "exploration: 0.9039699999999999, score: 11.0\n",
      "exploration: 0.90199, score: 23.0\n",
      "exploration: 0.90199, score: 18.0\n",
      "exploration: 0.901, score: 21.0\n",
      "exploration: 0.901, score: 12.0\n",
      "exploration: 0.90001, score: 16.0\n",
      "exploration: 0.90001, score: 14.0\n",
      "exploration: 0.8970400000000001, score: 14.0\n",
      "exploration: 0.89605, score: 12.0\n",
      "exploration: 0.89506, score: 15.0\n",
      "exploration: 0.89506, score: 35.0\n",
      "exploration: 0.89407, score: 21.0\n",
      "exploration: 0.89407, score: 11.0\n",
      "exploration: 0.89308, score: 19.0\n",
      "exploration: 0.89209, score: 13.0\n",
      "exploration: 0.89209, score: 18.0\n",
      "exploration: 0.89209, score: 9.0\n",
      "exploration: 0.8911, score: 33.0\n",
      "exploration: 0.8911, score: 22.0\n",
      "exploration: 0.89011, score: 17.0\n",
      "exploration: 0.89011, score: 10.0\n",
      "exploration: 0.88912, score: 53.0\n",
      "exploration: 0.88912, score: 25.0\n",
      "exploration: 0.88912, score: 18.0\n",
      "exploration: 0.88813, score: 22.0\n",
      "exploration: 0.88813, score: 16.0\n",
      "exploration: 0.88516, score: 17.0\n",
      "exploration: 0.88516, score: 28.0\n",
      "exploration: 0.88417, score: 16.0\n",
      "exploration: 0.88318, score: 44.0\n",
      "exploration: 0.88219, score: 13.0\n",
      "exploration: 0.8812, score: 16.0\n",
      "exploration: 0.88021, score: 14.0\n",
      "exploration: 0.87922, score: 12.0\n",
      "exploration: 0.87922, score: 15.0\n",
      "exploration: 0.87823, score: 18.0\n",
      "exploration: 0.87823, score: 14.0\n",
      "exploration: 0.87724, score: 27.0\n",
      "exploration: 0.87724, score: 27.0\n",
      "exploration: 0.87724, score: 29.0\n",
      "exploration: 0.87724, score: 27.0\n",
      "exploration: 0.87724, score: 15.0\n",
      "exploration: 0.87625, score: 17.0\n",
      "exploration: 0.87526, score: 20.0\n",
      "exploration: 0.87427, score: 14.0\n",
      "exploration: 0.87229, score: 16.0\n",
      "exploration: 0.87229, score: 19.0\n",
      "exploration: 0.87229, score: 17.0\n",
      "exploration: 0.8713, score: 37.0\n",
      "exploration: 0.8713, score: 18.0\n",
      "exploration: 0.8713, score: 31.0\n",
      "exploration: 0.87031, score: 8.0\n",
      "exploration: 0.86932, score: 13.0\n",
      "exploration: 0.86932, score: 12.0\n",
      "exploration: 0.86932, score: 15.0\n",
      "exploration: 0.86833, score: 22.0\n",
      "exploration: 0.86635, score: 23.0\n",
      "exploration: 0.86635, score: 11.0\n",
      "exploration: 0.86536, score: 39.0\n",
      "exploration: 0.8643700000000001, score: 21.0\n",
      "exploration: 0.8643700000000001, score: 13.0\n",
      "exploration: 0.86338, score: 15.0\n",
      "exploration: 0.86239, score: 17.0\n",
      "exploration: 0.86239, score: 15.0\n",
      "exploration: 0.86041, score: 30.0\n",
      "exploration: 0.85843, score: 19.0\n",
      "exploration: 0.85843, score: 18.0\n",
      "exploration: 0.85843, score: 14.0\n",
      "exploration: 0.85843, score: 13.0\n",
      "exploration: 0.85744, score: 15.0\n",
      "exploration: 0.85744, score: 14.0\n",
      "exploration: 0.85348, score: 51.0\n",
      "exploration: 0.85249, score: 13.0\n",
      "exploration: 0.85051, score: 42.0\n",
      "exploration: 0.85051, score: 12.0\n",
      "exploration: 0.84952, score: 34.0\n",
      "exploration: 0.84853, score: 31.0\n",
      "exploration: 0.84853, score: 23.0\n",
      "exploration: 0.84853, score: 21.0\n",
      "exploration: 0.84754, score: 11.0\n",
      "exploration: 0.84655, score: 55.0\n",
      "exploration: 0.8455600000000001, score: 17.0\n",
      "exploration: 0.84358, score: 26.0\n",
      "exploration: 0.84358, score: 27.0\n",
      "exploration: 0.84259, score: 33.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration: 0.8406100000000001, score: 17.0\n",
      "exploration: 0.8376399999999999, score: 40.0\n",
      "exploration: 0.8356600000000001, score: 22.0\n",
      "exploration: 0.8356600000000001, score: 25.0\n",
      "exploration: 0.8356600000000001, score: 17.0\n",
      "exploration: 0.83368, score: 17.0\n",
      "exploration: 0.83368, score: 39.0\n",
      "exploration: 0.83368, score: 30.0\n",
      "exploration: 0.83368, score: 52.0\n",
      "exploration: 0.83368, score: 31.0\n",
      "exploration: 0.83269, score: 32.0\n",
      "exploration: 0.8317, score: 12.0\n",
      "exploration: 0.8307100000000001, score: 39.0\n",
      "exploration: 0.82774, score: 22.0\n",
      "exploration: 0.82774, score: 31.0\n",
      "exploration: 0.82576, score: 41.0\n",
      "exploration: 0.82477, score: 34.0\n",
      "exploration: 0.82477, score: 26.0\n",
      "exploration: 0.82279, score: 46.0\n",
      "exploration: 0.82081, score: 25.0\n",
      "exploration: 0.81883, score: 15.0\n",
      "exploration: 0.81883, score: 30.0\n",
      "exploration: 0.81883, score: 48.0\n",
      "exploration: 0.81784, score: 18.0\n",
      "exploration: 0.81784, score: 16.0\n",
      "exploration: 0.8168500000000001, score: 26.0\n",
      "exploration: 0.8168500000000001, score: 14.0\n",
      "exploration: 0.81487, score: 18.0\n",
      "exploration: 0.8119000000000001, score: 47.0\n",
      "exploration: 0.80992, score: 31.0\n",
      "exploration: 0.80893, score: 66.0\n",
      "exploration: 0.80794, score: 30.0\n",
      "exploration: 0.80497, score: 12.0\n",
      "exploration: 0.80497, score: 44.0\n",
      "exploration: 0.80398, score: 21.0\n",
      "exploration: 0.80398, score: 32.0\n",
      "exploration: 0.80398, score: 45.0\n",
      "exploration: 0.79903, score: 18.0\n",
      "exploration: 0.79804, score: 36.0\n",
      "exploration: 0.79804, score: 50.0\n",
      "exploration: 0.79705, score: 22.0\n",
      "exploration: 0.79606, score: 51.0\n",
      "exploration: 0.79408, score: 87.0\n",
      "exploration: 0.79408, score: 31.0\n",
      "exploration: 0.79408, score: 24.0\n",
      "exploration: 0.7930900000000001, score: 61.0\n",
      "exploration: 0.7930900000000001, score: 41.0\n",
      "exploration: 0.7921, score: 12.0\n",
      "exploration: 0.79111, score: 28.0\n",
      "exploration: 0.78913, score: 43.0\n",
      "exploration: 0.78715, score: 36.0\n",
      "exploration: 0.78715, score: 18.0\n",
      "exploration: 0.78616, score: 19.0\n",
      "exploration: 0.78517, score: 9.0\n",
      "exploration: 0.78418, score: 37.0\n",
      "exploration: 0.78418, score: 31.0\n",
      "exploration: 0.78418, score: 44.0\n",
      "exploration: 0.78319, score: 45.0\n",
      "exploration: 0.7822, score: 12.0\n",
      "exploration: 0.77725, score: 57.0\n",
      "exploration: 0.77725, score: 42.0\n",
      "exploration: 0.7762600000000001, score: 23.0\n",
      "exploration: 0.77131, score: 26.0\n",
      "exploration: 0.77131, score: 47.0\n",
      "exploration: 0.77032, score: 23.0\n",
      "exploration: 0.76933, score: 23.0\n",
      "exploration: 0.76735, score: 24.0\n",
      "exploration: 0.76537, score: 39.0\n",
      "exploration: 0.76438, score: 48.0\n",
      "exploration: 0.76438, score: 62.0\n",
      "exploration: 0.76339, score: 20.0\n",
      "exploration: 0.7624, score: 48.0\n",
      "exploration: 0.76042, score: 48.0\n",
      "exploration: 0.76042, score: 36.0\n",
      "exploration: 0.75448, score: 39.0\n",
      "exploration: 0.75448, score: 30.0\n",
      "exploration: 0.75448, score: 50.0\n",
      "exploration: 0.75349, score: 24.0\n",
      "exploration: 0.75151, score: 12.0\n",
      "exploration: 0.75151, score: 58.0\n",
      "exploration: 0.74953, score: 18.0\n",
      "exploration: 0.74953, score: 37.0\n",
      "exploration: 0.74854, score: 39.0\n",
      "exploration: 0.7455700000000001, score: 19.0\n",
      "exploration: 0.74458, score: 100.0\n",
      "exploration: 0.74359, score: 41.0\n",
      "exploration: 0.73864, score: 98.0\n",
      "exploration: 0.73864, score: 15.0\n",
      "exploration: 0.73765, score: 39.0\n",
      "exploration: 0.73765, score: 61.0\n",
      "exploration: 0.7336900000000001, score: 44.0\n",
      "exploration: 0.7317100000000001, score: 53.0\n",
      "exploration: 0.72973, score: 33.0\n",
      "exploration: 0.72577, score: 60.0\n",
      "exploration: 0.72577, score: 26.0\n",
      "exploration: 0.72577, score: 69.0\n",
      "exploration: 0.72478, score: 27.0\n",
      "exploration: 0.7228000000000001, score: 38.0\n",
      "exploration: 0.72082, score: 78.0\n",
      "exploration: 0.72082, score: 44.0\n",
      "exploration: 0.72082, score: 49.0\n",
      "exploration: 0.72082, score: 62.0\n",
      "exploration: 0.71983, score: 30.0\n",
      "exploration: 0.71983, score: 14.0\n",
      "exploration: 0.71983, score: 18.0\n",
      "exploration: 0.71884, score: 53.0\n",
      "exploration: 0.7178500000000001, score: 27.0\n",
      "exploration: 0.71587, score: 50.0\n",
      "exploration: 0.71092, score: 33.0\n",
      "exploration: 0.7049799999999999, score: 50.0\n",
      "exploration: 0.70399, score: 68.0\n",
      "exploration: 0.7030000000000001, score: 85.0\n",
      "exploration: 0.70201, score: 48.0\n",
      "exploration: 0.70201, score: 21.0\n",
      "exploration: 0.70102, score: 20.0\n",
      "exploration: 0.6980500000000001, score: 51.0\n",
      "exploration: 0.6980500000000001, score: 23.0\n",
      "exploration: 0.69706, score: 28.0\n",
      "exploration: 0.69706, score: 29.0\n",
      "exploration: 0.69706, score: 22.0\n",
      "exploration: 0.69706, score: 24.0\n",
      "exploration: 0.6931, score: 37.0\n",
      "exploration: 0.69211, score: 69.0\n",
      "exploration: 0.6911200000000001, score: 99.0\n",
      "exploration: 0.69013, score: 81.0\n",
      "exploration: 0.6891400000000001, score: 22.0\n",
      "exploration: 0.68815, score: 38.0\n",
      "exploration: 0.68716, score: 45.0\n",
      "exploration: 0.6861700000000001, score: 53.0\n",
      "exploration: 0.68518, score: 70.0\n",
      "exploration: 0.6841900000000001, score: 19.0\n",
      "exploration: 0.6832, score: 10.0\n",
      "exploration: 0.68122, score: 16.0\n",
      "exploration: 0.68023, score: 40.0\n",
      "exploration: 0.67231, score: 67.0\n",
      "exploration: 0.67231, score: 48.0\n",
      "exploration: 0.67033, score: 56.0\n",
      "exploration: 0.67033, score: 20.0\n",
      "exploration: 0.66934, score: 69.0\n",
      "exploration: 0.66835, score: 87.0\n",
      "exploration: 0.66637, score: 31.0\n",
      "exploration: 0.6653800000000001, score: 81.0\n",
      "exploration: 0.66142, score: 27.0\n",
      "exploration: 0.65845, score: 60.0\n",
      "exploration: 0.65746, score: 15.0\n",
      "exploration: 0.65449, score: 29.0\n",
      "exploration: 0.6535, score: 16.0\n",
      "exploration: 0.65251, score: 32.0\n",
      "exploration: 0.64954, score: 36.0\n",
      "exploration: 0.6485500000000001, score: 32.0\n",
      "exploration: 0.6485500000000001, score: 24.0\n",
      "exploration: 0.64558, score: 23.0\n",
      "exploration: 0.6436000000000001, score: 38.0\n",
      "exploration: 0.6436000000000001, score: 59.0\n",
      "exploration: 0.6416200000000001, score: 80.0\n",
      "exploration: 0.64063, score: 26.0\n",
      "exploration: 0.63964, score: 53.0\n",
      "exploration: 0.6366700000000001, score: 61.0\n",
      "exploration: 0.6317200000000001, score: 74.0\n",
      "exploration: 0.6317200000000001, score: 55.0\n",
      "exploration: 0.62479, score: 78.0\n",
      "exploration: 0.6198400000000001, score: 33.0\n",
      "exploration: 0.61687, score: 42.0\n",
      "exploration: 0.61588, score: 55.0\n",
      "exploration: 0.60994, score: 34.0\n",
      "exploration: 0.6089500000000001, score: 46.0\n",
      "exploration: 0.60697, score: 25.0\n",
      "exploration: 0.60697, score: 95.0\n",
      "exploration: 0.60697, score: 91.0\n",
      "exploration: 0.60697, score: 51.0\n",
      "exploration: 0.60598, score: 84.0\n",
      "exploration: 0.60499, score: 37.0\n",
      "exploration: 0.6040000000000001, score: 37.0\n",
      "exploration: 0.60301, score: 89.0\n",
      "exploration: 0.60202, score: 119.0\n",
      "exploration: 0.60004, score: 25.0\n",
      "exploration: 0.59707, score: 23.0\n",
      "exploration: 0.59707, score: 57.0\n",
      "exploration: 0.5941000000000001, score: 111.0\n",
      "exploration: 0.5842, score: 87.0\n",
      "exploration: 0.58321, score: 116.0\n",
      "exploration: 0.5752900000000001, score: 113.0\n",
      "exploration: 0.5743, score: 66.0\n",
      "exploration: 0.57331, score: 89.0\n",
      "exploration: 0.56341, score: 69.0\n",
      "exploration: 0.56341, score: 47.0\n",
      "exploration: 0.55846, score: 49.0\n",
      "exploration: 0.5574700000000001, score: 80.0\n",
      "exploration: 0.5564800000000001, score: 93.0\n",
      "exploration: 0.5545, score: 112.0\n",
      "exploration: 0.55054, score: 66.0\n",
      "exploration: 0.5465800000000001, score: 103.0\n",
      "exploration: 0.5465800000000001, score: 51.0\n",
      "exploration: 0.5386599999999999, score: 108.0\n",
      "exploration: 0.5386599999999999, score: 69.0\n",
      "exploration: 0.5337099999999999, score: 69.0\n",
      "exploration: 0.52678, score: 118.0\n",
      "exploration: 0.5248, score: 126.0\n",
      "exploration: 0.52084, score: 74.0\n",
      "exploration: 0.51787, score: 87.0\n",
      "exploration: 0.51787, score: 200.0\n",
      "exploration: 0.51589, score: 90.0\n",
      "exploration: 0.5149, score: 93.0\n",
      "exploration: 0.51292, score: 63.0\n",
      "exploration: 0.51094, score: 96.0\n",
      "exploration: 0.50797, score: 67.0\n",
      "exploration: 0.505, score: 69.0\n",
      "exploration: 0.505, score: 103.0\n",
      "exploration: 0.50302, score: 95.0\n",
      "exploration: 0.5010399999999999, score: 63.0\n",
      "exploration: 0.50005, score: 200.0\n",
      "exploration: 0.4901500000000001, score: 65.0\n",
      "exploration: 0.48817, score: 69.0\n",
      "exploration: 0.47926, score: 85.0\n",
      "exploration: 0.47728000000000004, score: 127.0\n",
      "exploration: 0.47728000000000004, score: 108.0\n",
      "exploration: 0.47530000000000006, score: 76.0\n",
      "exploration: 0.47431, score: 85.0\n",
      "exploration: 0.46638999999999997, score: 61.0\n",
      "exploration: 0.46540000000000004, score: 51.0\n",
      "exploration: 0.4614400000000001, score: 73.0\n",
      "exploration: 0.45847000000000004, score: 143.0\n",
      "exploration: 0.45649000000000006, score: 83.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration: 0.4525300000000001, score: 23.0\n",
      "exploration: 0.4475800000000001, score: 100.0\n",
      "exploration: 0.4406500000000001, score: 81.0\n",
      "exploration: 0.43867, score: 77.0\n",
      "exploration: 0.42976000000000003, score: 110.0\n",
      "exploration: 0.4287700000000001, score: 190.0\n",
      "exploration: 0.4238200000000001, score: 90.0\n",
      "exploration: 0.42184, score: 84.0\n",
      "exploration: 0.41095000000000004, score: 200.0\n",
      "exploration: 0.41095000000000004, score: 148.0\n",
      "exploration: 0.40501, score: 104.0\n",
      "exploration: 0.39907000000000004, score: 107.0\n",
      "exploration: 0.39214000000000004, score: 109.0\n",
      "exploration: 0.38521000000000005, score: 200.0\n",
      "exploration: 0.38322999999999996, score: 28.0\n",
      "exploration: 0.37432, score: 92.0\n",
      "exploration: 0.36937, score: 157.0\n",
      "exploration: 0.3624400000000001, score: 129.0\n",
      "exploration: 0.36046, score: 107.0\n",
      "exploration: 0.35056, score: 162.0\n",
      "exploration: 0.35056, score: 154.0\n",
      "exploration: 0.34957000000000005, score: 80.0\n",
      "exploration: 0.3485800000000001, score: 200.0\n",
      "exploration: 0.3337300000000001, score: 120.0\n",
      "exploration: 0.33274000000000004, score: 148.0\n",
      "exploration: 0.3198700000000001, score: 200.0\n",
      "exploration: 0.3198700000000001, score: 200.0\n",
      "exploration: 0.30699999999999994, score: 172.0\n",
      "exploration: 0.30502000000000007, score: 118.0\n",
      "exploration: 0.30403, score: 96.0\n",
      "exploration: 0.3030400000000001, score: 200.0\n",
      "exploration: 0.29710000000000014, score: 143.0\n",
      "exploration: 0.29017000000000004, score: 200.0\n",
      "exploration: 0.27928, score: 200.0\n",
      "exploration: 0.27631000000000006, score: 200.0\n",
      "exploration: 0.27136000000000005, score: 160.0\n",
      "exploration: 0.2634400000000001, score: 200.0\n",
      "exploration: 0.26047, score: 124.0\n",
      "exploration: 0.26047, score: 200.0\n",
      "exploration: 0.2584900000000001, score: 200.0\n",
      "exploration: 0.25056999999999996, score: 162.0\n",
      "exploration: 0.24958000000000002, score: 200.0\n",
      "exploration: 0.24265000000000014, score: 200.0\n",
      "exploration: 0.2347300000000001, score: 141.0\n",
      "exploration: 0.2278000000000001, score: 179.0\n",
      "exploration: 0.22582000000000002, score: 200.0\n",
      "exploration: 0.1941400000000001, score: 200.0\n",
      "exploration: 0.18721, score: 200.0\n",
      "exploration: 0.17137000000000002, score: 200.0\n",
      "exploration: 0.1684, score: 184.0\n",
      "exploration: 0.16444000000000003, score: 200.0\n",
      "exploration: 0.16246000000000016, score: 200.0\n",
      "exploration: 0.15256000000000014, score: 200.0\n",
      "exploration: 0.15156999999999998, score: 200.0\n",
      "exploration: 0.15058000000000005, score: 200.0\n",
      "exploration: 0.13573000000000002, score: 200.0\n",
      "exploration: 0.13473999999999997, score: 200.0\n",
      "exploration: 0.12187000000000003, score: 200.0\n",
      "exploration: 0.12187000000000003, score: 200.0\n",
      "exploration: 0.1090000000000001, score: 200.0\n",
      "exploration: 0.10702, score: 200.0\n",
      "exploration: 0.10602999999999996, score: 200.0\n",
      "exploration: 0.10504000000000013, score: 200.0\n",
      "exploration: 0.09910000000000008, score: 200.0\n",
      "exploration: 0.09216999999999997, score: 200.0\n",
      "exploration: 0.08128000000000002, score: 200.0\n",
      "exploration: 0.0783100000000001, score: 200.0\n",
      "exploration: 0.07336000000000009, score: 200.0\n",
      "exploration: 0.06544000000000005, score: 200.0\n",
      "exploration: 0.062469999999999914, score: 200.0\n",
      "exploration: 0.062469999999999914, score: 200.0\n",
      "exploration: 0.060490000000000044, score: 200.0\n",
      "exploration: 0.05257000000000012, score: 200.0\n",
      "exploration: 0.05158000000000007, score: 200.0\n",
      "exploration: 0.04465000000000008, score: 200.0\n",
      "exploration: 0.03673000000000004, score: 200.0\n",
      "exploration: 0.02980000000000005, score: 200.0\n",
      "exploration: 0.027820000000000178, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 196.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 191.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 189.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 182.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 190.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 195.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 186.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 186.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 181.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 186.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 168.0\n",
      "exploration: 0.01, score: 194.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 179.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 182.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 176.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 194.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 193.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n",
      "exploration: 0.01, score: 200.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8e856b533efd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_envs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-34715c0f68b6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(T, num_envs)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms_t_next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecay_epsilon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mepisode_rewards\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b775ed088030>\u001b[0m in \u001b[0;36mexperience_replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_t_next\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_t\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mQ_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_t_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mQ_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_t\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0md_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mQ_next\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mQ_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    706\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0;31m# Eager execution on data tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m           with base_layer_utils.autocast_context_manager(\n",
      "\u001b[0;32m/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mname_scope\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[0mName\u001b[0m \u001b[0mscope\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \"\"\"\n\u001b[0;32m--> 739\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r_t = train(T=10000, num_envs=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
