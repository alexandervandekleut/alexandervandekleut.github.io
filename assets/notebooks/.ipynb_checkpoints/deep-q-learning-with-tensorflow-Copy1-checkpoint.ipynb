{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Deep $Q$-learning\n",
    "\n",
    "We have spent the time to learn about differentiable function approximators, $Q$-learning as a regression problem, and autodifferentiation in `tensorflow` for optimization. We have also now seen a complete `tensorflow` program that demonstrates tabular $Q$-learning, using the idea of $Q$-learning as a regression problem. Finally, we are ready to approach **deep $Q$-learning**: using **deep neural networks** to learn the $Q$-function.\n",
    "\n",
    "Recall our original motivation for learning about function approximators: similar inputs produce similar outputs. We need this property because for environments with extremely large or infinite state spaces, we are likely to visit each state at most once. Thus, using a table to learn the $Q$ function is infeasible. Instead, we use a differentiable function approximator so that two similar states will produce two similar outputs.\n",
    "\n",
    "The most popular class of differentiable function approximators used by machine learning researchers today is **deep neural networks**. I assume that, as someone interested in deep reinforcement learning, you have an idea on how neural networks work. There are plenty of great resources out there, but I expect you to be familiar with the concepts of\n",
    "\n",
    "- dense (fully connected) layers\n",
    "- convolutional layers\n",
    "- activation functions\n",
    "\n",
    "If you are an advanced machine learning user, you may have heard of techniques like *activity regularization* and *dropout*. For reasons we aren't too sure of yet, these techniques (often applied to classification problems in supervised learning) [*don't work well with reinforcement learning*](https://www.alexirpan.com/2018/02/14/rl-hard.html) (or at least, don't seem to improve performance). Furthermore, really deep architectures like ResNet don't improve performance over smaller networks with one or two hidden layers.\n",
    "\n",
    "The idea with using neural networks for $Q$-learning is that, rather than inputting $(s_t, a_t)$ into the network and producing a scalar output for $Q(s_t, a_t)$, we instead input just the state $s_t$ and produce a **vector** of $Q$ values for each action $a_t$. Since our network is a differentiable function approximator parametrized by some set of parameters $\\theta$, we write $Q_\\theta$:\n",
    "\n",
    "![Q-network](../images/q-network.png)\n",
    "\n",
    " Given these parameters $\\theta$, we can define a loss function that we want to minimize with respect to the network parameters.\n",
    " \n",
    " $$\n",
    " L(\\theta) = \\mathbb{E}_{a_t \\sim \\pi}[(y_i - Q_\\theta(s_t, a_t))^2]\n",
    " $$\n",
    " \n",
    " where the TD target is $y_i$:\n",
    " \n",
    " $$\n",
    " y_i = \\mathbb{E}_{a_{t+1} \\sim \\pi} \\left[ r_t + \\gamma \\max_{a_{t+1}}Q_\\theta(s_{t+1}, a_{t+1}) \\big\\vert s_t, a_t \\right]\n",
    " $$\n",
    " \n",
    " Training the neural network would consist of the following sequence of events:\n",
    " \n",
    " 1. The agent in state $s_t$ calculates $Q_\\theta (s_t, a_t)$ using network parameters $\\theta$ for each possible $a_t$. Using the greedy policy, it selects the action $a_t$ that maximizes $Q_\\theta (s_t, a_t)$.\n",
    " 2. As a result of choosing this action, the state transitions to state $s_{t+1}$. The agent recieves a reward $r_t$ as a result.\n",
    " 3. The agent is now in state $s_{t+1}$ calculates $Q_\\theta(s_{t+1}, a_{t+1})$ using network parameters $\\theta$ for each possible $a_{t+1}$. The maximal value of $Q_\\theta (s_{t+1}, a_{t+1})$ is chosen.\n",
    " 4. The network is trained to minimize the loss, with $Q_\\theta (s_t, a_t)$ being the prediction of the network, and with $y_i$ being the reward for transitioning and the discounted maximal $Q$ value for state $s_{t+1}$ determined in step $4$ (i.e., $r_t + \\gamma \\max_{a_{t+1}}Q_\\theta (s_{t+1}, a_{t+1}))$.\n",
    "\n",
    "![Q network data collection and training image](../images/state-transition-q-learning-loss.png)\n",
    "\n",
    "***\n",
    "### Target Networks\n",
    "\n",
    "You may have noticed above that the network is trying to predict its own output. This kind of learning is unstable, meaning performance can quickly deteriorate (to even worse than random). One reason for this is that the neural network is differentiable. When we modify the parameters $\\theta$ while training the network, we change the predictions for similar states to that which we just trained on. Since consecutive states tend to be similar, this can lead to an explosion in predicted values. Research has shown that training can be stabilized by using two networks: $\\theta$ and $\\theta_\\text{targ}$. Instead of one set of parameters, we have two (i.e., we have two neural networks). We call the second network ($\\theta_\\text{targ}$) the **target network**, and it uses the parameters from the $Q$-network that synchronize with the current $Q$-network every $n_\\theta$ timesteps.\n",
    "\n",
    "We also define two policies:\n",
    "1. $\\pi$: The **behaviour policy** that uses the $Q$-network ($Q_\\theta (s_t,a_t)$) and is updated every time step.\n",
    "2. $\\pi_\\text{targ}$: The **target policy** that uses the target network ($Q_{\\theta_\\text{targ}} (s_{t+1},a_{t+1})$) and is updated to match $\\pi$ (i.e., $\\theta_\\text{targ}$ is updated to match $\\theta$) every $n_\\theta$ timesteps.\n",
    "\n",
    "Since the kind of predictions made by the target network $\\theta_\\text{targ}$ are static for $n_\\theta$ timesteps, training becomes stabilized.\n",
    "\n",
    "As a result, we get a new formulation of the loss:\n",
    "$$\n",
    "L(\\theta) = \\mathbb{E}_{a \\sim \\pi} \\left[ (y_i - Q_\\theta(s_t,a_t))^2 \\right]\n",
    "$$\n",
    "where the TD target is $y_i$:\n",
    "$$\n",
    "y_i = \\mathbb{E}_{a_{t+1} \\sim \\pi_\\text{targ}} \\left[ r_t + \\gamma \\max_{a_{t+1}}Q_{\\theta_\\text{targ}}(s_{t+1}, a_{t+1}) \\big\\vert s_t, a_t \\right]\n",
    "$$\n",
    "\n",
    "![Q network with target network image](../images/state-transition-q-learning-loss-target-networks.png)\n",
    "\n",
    "***\n",
    "### Experience Replay\n",
    "When we update our $Q$-network, we do it after every state transition (i.e., we do it **{online}**. Recall that we are using gradient descent to train the network parameters $\\theta$. One problem with training online is that we get a biased, high variance estimate for the gradient. A better approach would involve taking the mean gradient estimate of the loss over many pairs of $Q_\\theta(s,a)$ and TD targets. Furthermore, by training the network only on the most recent state transition, we are only making the network better at predicting the most recent TD target. This can undo some of the progress made training the network on earlier transitions. This problem is known as **catastrophic forgetting**.\n",
    "\n",
    "We can reduce the noise and bias in our gradient estimates by including an **experience replay buffer** $\\mathcal{D}$ that stores transitions\n",
    "$$\n",
    "\\langle s_t, a_t, r_t, s_{t+1} \\rangle\n",
    "$$\n",
    "Note that we do not need to store $a_{t+1}$ since our network will choose $a_{t+1}$ based on $\\pi$ anyways. We then train the network by taking batches of transitions from $\\mathcal{D}$. For each transition, we use the $Q$-network to predict $Q_\\theta (s_t,a_t)$ and to consequently choose an action $a_t \\sim \\pi$, and we use the target network to predict $Q_{\\theta_\\text{targ}}(s_{t+1},a_{t+1})$ and to consequently choose an action $a_{t+1} \\sim \\pi_\\text{targ}$. Over all transitions in the batch, we calculate the gradient of the loss $L(\\theta)$. We take the average of these gradients and update the network parameters.\n",
    "\n",
    "\n",
    "Combining target networks with experience replay provided the necessary stability to [play atari games directly from pixels](https://arxiv.org/abs/1312.5602).\n",
    "\n",
    "***\n",
    "##### A note about the Bellman equation and Terminal States\n",
    "\n",
    "Note that the idea of a *terminal state* is not included in the standard definition of a Markov decision process. However, the reward for all next states if the current state is terminal should be $0$. Therefore, we consider the following modification to the TD value:\n",
    "$$\n",
    "r_t + (1- d_t) Q(s_{t+1}, a_{t+1})\n",
    "$$\n",
    "where $d_t$ stands for 'done', and is $1$ when the $s_t$ is terminal and is $0$ otherwise. Then, if the environment is done, the TD target becomes just $r_t$. We include the `done` flag in our batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, state_shape, num_actions, size=100000):\n",
    "        self.s_t_buf = np.zeros((size, *state_shape), dtype=np.float32)\n",
    "        self.s_t_next_buf = np.zeros((size, *state_shape), dtype=np.float32)\n",
    "        self.a_t_buf = np.zeros((size), dtype=np.int32)\n",
    "        self.r_t_buf = np.zeros((size), dtype=np.int32)\n",
    "        self.d_t_buf = np.zeros((size), dtype=np.int32)\n",
    "        self.pointer = 0\n",
    "        self.filled = 0\n",
    "        self.size = size\n",
    "        \n",
    "    def store_transition(self, s_t, a_t, r_t, s_t_next, d_t):\n",
    "        self.s_t_buf[self.pointer] = s_t\n",
    "        self.a_t_buf[self.pointer] = a_t\n",
    "        self.r_t_buf[self.pointer] = r_t\n",
    "        self.s_t_next_buf[self.pointer] = s_t_next\n",
    "        self.d_t_buf[self.pointer] = d_t\n",
    "        self.pointer = (self.pointer + 1) % self.size\n",
    "        self.filled = min(self.filled+1, self.size)\n",
    "        \n",
    "    def get(self, number=32):\n",
    "        number = min(number, self.filled)\n",
    "        indices = np.random.choice(np.arange(self.filled), number, replace=False)\n",
    "        return self.s_t_buf[indices], self.a_t_buf[indices], self.r_t_buf[indices], self.s_t_next_buf[indices], self.d_t_buf[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, space_shape, num_actions, \n",
    "                 epsilon_i=1.0, \n",
    "                 epsilon_f=0.0, \n",
    "                 n_epsilon=10000, \n",
    "                 alpha=1e-1, \n",
    "                 gamma = 0.99,\n",
    "                 optimizer = tf.train.AdamOptimizer,\n",
    "                 ddqn=True\n",
    "                ):\n",
    "        tf.reset_default_graph()\n",
    "        self.epsilon = tf.get_variable(\"epsilon\", initializer=tf.constant(epsilon_i, dtype=tf.float32))\n",
    "        \n",
    "        self.s_t_ph = s_t = tf.placeholder(dtype=tf.float32, shape=(None, *space_shape), name=\"state_placeholder\")\n",
    "        self.r_t_ph = r_t = tf.placeholder(dtype=tf.float32, shape=(None, ), name=\"reward_placeholder\")\n",
    "        self.a_t_ph = a_t = tf.placeholder(dtype=tf.int32, shape=(None, ), name=\"action_placeholder\")\n",
    "        self.s_t_next_ph = s_t_next = tf.placeholder(dtype=tf.float32, shape=(None, *space_shape), name=\"state_next_placeholder\")\n",
    "        self.d_t_ph = d_t = tf.placeholder(dtype=tf.float32, shape=(None, ), name=\"done_placeholder\")\n",
    "        \n",
    "        # use scope to allow updating network weights later\n",
    "        with tf.variable_scope(\"Q\"):\n",
    "            Q = tf.keras.layers.Dense(num_actions, kernel_initializer='zeros', use_bias=False, name=\"Q\")(s_t)\n",
    "        with tf.variable_scope(\"Q_targ\"):\n",
    "            Q_targ = tf.keras.layers.Dense(num_actions, kernel_initializer='zeros', use_bias=False, name=\"Q_targ\")(s_t_next)\n",
    "        \n",
    "        self.Q_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"Q\")\n",
    "        self.Q_targ_params = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"Q_targ\")\n",
    "        self.sync = [Q_targ_var.assign(Q_var) for Q_targ_var, Q_var in zip(self.Q_targ_params, self.Q_params)]\n",
    "\n",
    "        p = tf.random_uniform(shape=(), minval=0, maxval=1, dtype=tf.float32) \n",
    "        self.act = tf.cond(p < self.epsilon,\n",
    "              lambda: tf.random_uniform(shape=(1,), minval=0, maxval=num_actions, dtype=tf.int32),\n",
    "              lambda: tf.argmax(Q, output_type=tf.int32, axis=1)) \n",
    "        \n",
    "        a_t_next = tf.cond(p < self.epsilon,\n",
    "              lambda: tf.random_uniform(shape=(1,), minval=0, maxval=num_actions, dtype=tf.int32),\n",
    "              lambda: tf.argmax(Q if ddqn else Q_targ, output_type=tf.int32, axis=1))\n",
    "\n",
    "        self.Q_pred = Q_pred = tf.reduce_sum(tf.one_hot(a_t, num_actions)*Q, axis=1)\n",
    "        self.Q_targ_pred = Q_targ_pred = tf.reduce_sum(tf.one_hot(a_t_next, num_actions)*Q_targ, axis=1)\n",
    "        \n",
    "        TD = r_t + (1-d_t)*gamma*Q_targ_pred\n",
    "        TD = tf.stop_gradient(TD)\n",
    "        self.loss = tf.reduce_mean(0.5*(TD - Q_pred)**2)\n",
    "        self.update = optimizer(alpha).minimize(self.loss)\n",
    "\n",
    "        self.decay_epsilon = tf.assign(self.epsilon,\n",
    "              tf.maximum( \n",
    "                  epsilon_f,\n",
    "                  self.epsilon - (epsilon_i - epsilon_f)/n_epsilon)                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotFrozenLake(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        self.num_states = env.observation_space.n\n",
    "        self.observation_space = gym.spaces.Box(0, 1, (env.observation_space.n,))\n",
    "        \n",
    "    def observation(self, obs):\n",
    "        obs_oh = np.zeros(self.num_states)\n",
    "        obs_oh[obs] = 1\n",
    "        return obs_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/rl-lessons/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda3/envs/rl-lessons/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "99.0%\r"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v0\")\n",
    "env = OneHotFrozenLake(env)\n",
    "\n",
    "space_shape = env.observation_space.shape\n",
    "num_actions = env.action_space.n\n",
    "\n",
    "buffer = ReplayBuffer(space_shape, num_actions)\n",
    "\n",
    "agent = Agent(space_shape, num_actions, gamma = 0.95, alpha=0.5, optimizer=tf.train.GradientDescentOptimizer)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    T = 100000\n",
    "    batch_size = 32\n",
    "    sync_every = 100\n",
    "    s_t = env.reset()\n",
    "\n",
    "    rewards = []\n",
    "    episode_rewards = 0\n",
    "\n",
    "    for t in range(T):\n",
    "        if t%sync_every == 0:\n",
    "            sess.run(agent.sync)\n",
    "        \n",
    "        if (t%1000 == 0):\n",
    "            print(f'{100*t/T}%', end='\\r')\n",
    "        a_t = sess.run(agent.act, \n",
    "                       feed_dict = {\n",
    "                            agent.s_t_ph: s_t.reshape(1, *s_t.shape)\n",
    "        })        \n",
    "\n",
    "        a_t = a_t[0]\n",
    "        \n",
    "        s_t_next, r_t, d_t, info = env.step(a_t)\n",
    "\n",
    "        buffer.store_transition(s_t, a_t, r_t, s_t_next, d_t)\n",
    "\n",
    "        sess.run(agent.decay_epsilon)\n",
    "        s_t = s_t_next\n",
    "        episode_rewards += r_t\n",
    "        \n",
    "\n",
    "        if d_t:\n",
    "            rewards.append(episode_rewards)\n",
    "            episode_rewards = 0\n",
    "            s_t = env.reset()\n",
    "            \n",
    "        if t < batch_size:\n",
    "            continue\n",
    "            \n",
    "        s_t_train, a_t_train, r_t_train, s_t_next_train, d_t_train = buffer.get(batch_size)\n",
    "\n",
    "        sess.run([agent.loss, agent.update],\n",
    "        feed_dict = {\n",
    "            agent.s_t_ph:s_t_train,\n",
    "            agent.a_t_ph:a_t_train,\n",
    "            agent.r_t_ph:r_t_train,\n",
    "            agent.s_t_next_ph:s_t_next_train,\n",
    "            agent.d_t_ph:d_t_train\n",
    "        })            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a31a5e8d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "window = 100\n",
    "running_mean_rewards = pd.Series(rewards, name='q-learning').rolling(window=window).mean()[window-1:] # this slicing is because the first window-1 elements are NaN from the rolling operation.\n",
    "sns.lineplot(data=running_mean_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
